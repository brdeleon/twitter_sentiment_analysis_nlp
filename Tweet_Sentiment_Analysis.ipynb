{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7a2085",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "Author: Brenda De Leon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e7494",
   "metadata": {},
   "source": [
    "<img src=“url/filename.gif” alt=“Alt text” title=“Title text” />\n",
    "### Overview\n",
    "### Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea053090",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "#### Data Source\n",
    "##### Data Limitations:\n",
    "#### Features\n",
    "#### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66bbab70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing relevant libraries\n",
    "# !pip install wordcloud\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk import FreqDist \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f001c7a5",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26d2336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data\n",
    "df = pd.read_csv('data/judge_1377884607_tweet_product_company.csv')\n",
    "# previewing data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d5af60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8721 entries, 0 to 8720\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          8720 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3169 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  8721 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 204.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# viewing columns, # of columns, dtypes, # of rows, # of non nulls\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1525e171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8720</td>\n",
       "      <td>3169</td>\n",
       "      <td>8721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8693</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>910</td>\n",
       "      <td>5156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet_text  \\\n",
       "count                                                8720   \n",
       "unique                                               8693   \n",
       "top     RT @mention Marissa Mayer: Google Will Connect...   \n",
       "freq                                                    5   \n",
       "\n",
       "       emotion_in_tweet_is_directed_at  \\\n",
       "count                             3169   \n",
       "unique                               9   \n",
       "top                               iPad   \n",
       "freq                               910   \n",
       "\n",
       "       is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "count                                                8721  \n",
       "unique                                                  4  \n",
       "top                    No emotion toward brand or product  \n",
       "freq                                                 5156  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting data value ranges\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e6bf6",
   "metadata": {},
   "source": [
    "We will rename column titles to make them more condensed and descriptive. We will preview column values to assure most accurate new titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6031f58d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RT @mention Marissa Mayer: Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxsw                                      5\n",
       "RT @mention Marissa Mayer: Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #SXSW                                      4\n",
       "RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw                                                   4\n",
       "RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #SXSW                                                   3\n",
       "#SXSW is just starting, #CTIA is around the corner and #googleio is only a hop skip and a jump from there, good time to be an #android fan          2\n",
       "RT @mention RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw                                       2\n",
       "Really enjoying the changes in Gowalla 3.0 for Android! Looking forward to seeing what else they &amp; Foursquare have up their sleeves at #SXSW    2\n",
       "Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw                                                               2\n",
       "Win free ipad 2 from webdoc.com #sxsw RT                                                                                                            2\n",
       "Before It Even Begins, Apple Wins #SXSW {link}                                                                                                      2\n",
       "Oh. My. God. The #SXSW app for iPad is pure, unadulterated awesome. It's easier to browse events on iPad than on the website!!!                     2\n",
       "Need to buy an iPad2 while I'm in Austin at #sxsw. Not sure if I'll need to Q up at an Austin Apple store?                                          2\n",
       "Marissa Mayer: Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxsw                                                  2\n",
       "RT @mention RT @mention It's not a rumor: Apple is opening up a temporary store in downtown Austin for #SXSW and the iPad 2 launch {link}           2\n",
       "I just noticed DST is coming this weekend. How many iPhone users will be an hour late at SXSW come Sunday morning? #SXSW #iPhone                    2\n",
       "Win free iPad 2 from webdoc.com #sxsw RT                                                                                                            2\n",
       "RT @mention ��� GO BEYOND BORDERS! ��_ {link} ��_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter                                            2\n",
       "Counting down the days to #sxsw plus strong Canadian dollar means stock up on Apple gear                                                            2\n",
       "RT @mention ��� Happy Woman's Day! Make love, not fuss! ��_ {link} ��_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter                       2\n",
       "Such suspense! RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw                                    1\n",
       "Not going to #SXSW ? Doesnt matter, its not the only place giving away #Apple products :) {link}                                                    1\n",
       "RT @mention @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} #sxsw                                          1\n",
       "One lone dude awaits iPad 2 at Apple�۪s #SXSW store: Apple likely expected a bigger crowd forming at its South by ... {link}                        1\n",
       "@mention What's the wait time lookin like? The Apple Store up north is already sold out, any word on the #SXSW inventory?                           1\n",
       "RT @mention The @mention / @mention party was without a doubt the best party I've ever been to in #SXSW. Well done!                                 1\n",
       "Name: tweet_text, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing 'tweet_text' values\n",
    "df['tweet_text'].value_counts(dropna=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a91541d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                5552\n",
       "iPad                                910\n",
       "Apple                               640\n",
       "iPad or iPhone App                  451\n",
       "Google                              412\n",
       "iPhone                              288\n",
       "Other Google product or service     282\n",
       "Android App                          78\n",
       "Android                              74\n",
       "Other Apple product or service       34\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing 'emotion_in_tweet_is_directed_at' values\n",
    "df['emotion_in_tweet_is_directed_at'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95b0b989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5156\n",
       "Positive emotion                      2869\n",
       "Negative emotion                       545\n",
       "I can't tell                           151\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing 'is_there_an_emotion_directed_at_a_brand_or_product' values\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5600b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns \n",
    "df = df.rename(columns = {'is_there_an_emotion_directed_at_a_brand_or_product':'Sentiment',\n",
    "                          'tweet_text':'Tweet', \n",
    "                          'emotion_in_tweet_is_directed_at':'Product_or_Service'}\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35e07c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet                    1\n",
       "Product or Service    5552\n",
       "Sentiment                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d790b3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping single null in tweet column\n",
    "df.dropna(subset=['Tweet'], inplace = True)\n",
    "# confirming null was dropped\n",
    "df['Tweet'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208dfc21",
   "metadata": {},
   "source": [
    "Will need to address remaining null values later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e3b79e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3082eec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8694"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print length of 'Tweet' column\n",
    "print(len(df['Tweet']))\n",
    "# unique value count for 'Tweet' column\n",
    "len(df['Tweet'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf7ed1",
   "metadata": {},
   "source": [
    "After previewing column values and value counts, duplicates are retweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5442d0",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "The data needs to be able to fit a scikit-learn model. We will standardize the case of the data, use a tokenizer to convert the full tweets into lists of individual words, and address the remaining nulls. We will then compare the raw word frequency distributions of each sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split tweet_text to create unprocessed_text - we'll make a visualization with this and compare it with preprocessed_text\n",
    "df['unprocessed_text'] = df['tweet_text'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22b7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838eab2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "106bf3b8",
   "metadata": {},
   "source": [
    "### Build and Evaluate a Baseline Model with TfidfVectorizer and MultinomialNB\n",
    "Ultimately all data must be in numeric form in order to be able to fit a scikit-learn model. So we'll use a tool from sklearn.feature_extraction.text to convert all data into a vectorized format.\n",
    "\n",
    "Initially we'll keep all of the default parameters for both the vectorizer and the model, in order to develop a baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Requirements\n",
    "1. Load the Data\n",
    "Use pandas and sklearn.datasets to load the train and test data into appropriate data structures. Then get a sense of what is in this dataset by visually inspecting some samples.\n",
    "\n",
    "2. Perform Data Cleaning and Exploratory Data Analysis with nltk\n",
    "Standardize the case of the data and use a tokenizer to convert the full posts into lists of individual words. Then compare the raw word frequency distributions of each category.\n",
    "\n",
    "3. Build and Evaluate a Baseline Model with TfidfVectorizer and MultinomialNB\n",
    "Ultimately all data must be in numeric form in order to be able to fit a scikit-learn model. So we'll use a tool from sklearn.feature_extraction.text to convert all data into a vectorized format.\n",
    "\n",
    "Initially we'll keep all of the default parameters for both the vectorizer and the model, in order to develop a baseline score.\n",
    "\n",
    "4. Iteratively Perform and Evaluate Preprocessing and Feature Engineering Techniques\n",
    "Here you will investigate three techniques, to determine whether they should be part of our final modeling process:\n",
    "\n",
    "Removing stopwords\n",
    "Using custom tokens\n",
    "Domain-specific feature engineering\n",
    "Increasing max_features\n",
    "5. Evaluate a Final Model on the Test Set\n",
    "Once you have chosen a final modeling process, fit it on the full training data and evaluate it on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
